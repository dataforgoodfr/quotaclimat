{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Scrapping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3120d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data_public/sitemap_dumps/'\n",
    "\n",
    "# Import des librairies\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# créer deux listes contenant les noms des fichiers scrappés\n",
    "tv_sources = os.listdir(base_path+'media_type=tv')\n",
    "webpress_sources = os.listdir(base_path+'media_type=webpress')\n",
    "filelist_tv = []\n",
    "for source in tv_sources:\n",
    "    for root, dirs, files in os.walk(base_path+'media_type=tv/'+source):\n",
    "\t    for file in files:\n",
    "            #append the file name to the list\n",
    "\t\t    filelist_tv.append(os.path.join(root,file))\n",
    "\n",
    "filelist_webpress = []\n",
    "for source in webpress_sources:\n",
    "    for root, dirs, files in os.walk(base_path+'media_type=webpress/'+source):\n",
    "        for file in files:\n",
    "            #append the file name to the list\n",
    "            filelist_webpress.append(os.path.join(root,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6bd80c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Importer les fichiers parquet dans un dataframe pandas\n",
    "df_tv = pd.DataFrame()\n",
    "for file in filelist_tv:\n",
    "    df_tv = df_tv.append(pd.read_parquet(file, engine='pyarrow'))\n",
    "\n",
    "df_webpress = pd.DataFrame()\n",
    "for file in filelist_webpress:\n",
    "    df_webpress = df_webpress.append(pd.read_parquet(file, engine='pyarrow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d3a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténer les deux dataframes\n",
    "\n",
    "df = pd.concat([df_tv, df_webpress], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2c0786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de valeurs manquantes par colonnes pour le dataframe : \n",
      "url                       0.000000\n",
      "publication_name          0.000000\n",
      "publication_language      0.000000\n",
      "news_publication_date     0.000000\n",
      "news_title                0.000000\n",
      "image_loc                 1.694514\n",
      "image_caption             8.705107\n",
      "sitemap                   0.000000\n",
      "sitemap_size_mb           0.000000\n",
      "download_date             0.000000\n",
      "media                     0.000000\n",
      "section                   0.000000\n",
      "media_type               75.983981\n",
      "news                     56.982603\n",
      "news_publication         56.982603\n",
      "image                    57.490742\n",
      "news_keywords            65.608044\n",
      "etag                     75.669624\n",
      "sitemap_last_modified    54.207217\n",
      "lastmod                  57.908449\n",
      "news_genres              99.829903\n",
      "news_access              99.608130\n",
      "changefreq               95.047800\n",
      "priority                 95.047800\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# vérifier les pourcentages de valeurs manquantes par colonnes\n",
    "print('Pourcentage de valeurs manquantes par colonnes pour le dataframe : ')\n",
    "print(df.isnull().sum()/df.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f36d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les colonnes avec plus de 50% de valeurs manquantes\n",
    "\n",
    "df = df.dropna(axis=1, thresh=df.shape[0]*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25507eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all dates matching the pattern `\\d{2}\\/\\d{2}` in news_title\n",
    "import re\n",
    "\n",
    "df['news_title'] = df['news_title'].apply(lambda x: re.sub(r'\\d{2}\\/\\d{2}', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17830437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                              object\n",
       "publication_name                 object\n",
       "publication_language             object\n",
       "news_publication_date    datetime64[ns]\n",
       "news_title                       object\n",
       "image_loc                        object\n",
       "image_caption                    object\n",
       "sitemap                          object\n",
       "sitemap_size_mb                 float64\n",
       "download_date            datetime64[ns]\n",
       "media                            object\n",
       "section                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns dtype\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1857dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir la colonne section de type array en type list\n",
    "\n",
    "df['section'] = df['section'].apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3383d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tech', 'bons-plans']\n"
     ]
    }
   ],
   "source": [
    "#print the first value of the column section\n",
    "\n",
    "print(df['section'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7691dfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de bulletins météos dans le dataframe : \n",
      "1.2057531651020585\n"
     ]
    }
   ],
   "source": [
    "# Chercher les bulletins météos dans la colonne section\n",
    "\n",
    "df['is_weather'] = df['section'].apply(lambda x: 'meteo' in x)\n",
    "\n",
    "\n",
    "\n",
    "print('Pourcentage de bulletins météos dans le dataframe : ')\n",
    "print(df['is_weather'].sum()/df.shape[0]*100)\n",
    "\n",
    "# Extraire les bulletins météos dans un dataframe séparé\n",
    "\n",
    "df_weather = df[df['is_weather'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e82afe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage d'articles ayant \"JT\" dans le titre : \n",
      "0.08827835673068642\n"
     ]
    }
   ],
   "source": [
    "# Chercher les articles ayant 'JT' dans le titre\n",
    "\n",
    "df['is_jt'] = df['news_title'].apply(lambda x: 'JT' in x)\n",
    "\n",
    "print('Pourcentage d\\'articles ayant \"JT\" dans le titre : ')\n",
    "print(df['is_jt'].sum()/df.shape[0]*100)\n",
    "\n",
    "# Extraire les articles ayant 'JT' dans le titre dans un dataframe séparé\n",
    "\n",
    "df_jt = df[df['is_jt'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0be3f492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de is_replay dans le dataframe : \n",
      "12.259925932305572\n"
     ]
    }
   ],
   "source": [
    "# Chercher les replay-emissions dans la colonne section\n",
    "\n",
    "df['is_replay'] = df['section'].apply(lambda x: 'replay-emissions' in x)\n",
    "\n",
    "\n",
    "\n",
    "print('Pourcentage de is_replay dans le dataframe : ')\n",
    "print(df['is_replay'].sum()/df.shape[0]*100)\n",
    "\n",
    "# Extraire les bulletins météos dans un dataframe séparé\n",
    "\n",
    "df_replay = df[df['is_replay'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd7da4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de is_bonsoir dans le dataframe : \n",
      "0.4823012660408234\n"
     ]
    }
   ],
   "source": [
    "# Chercher les replay-emissions dans la colonne section\n",
    "\n",
    "df['is_bonsoir'] = df['section'].apply(lambda x: 'bonsoir-lyon' in x)\n",
    "\n",
    "\n",
    "\n",
    "print('Pourcentage de is_bonsoir dans le dataframe : ')\n",
    "print(df['is_bonsoir'].sum()/df.shape[0]*100)\n",
    "\n",
    "# Extraire les bulletins météos dans un dataframe séparé\n",
    "\n",
    "df_bonsoir = df[df['is_bonsoir'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a8804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9d039c162d29c1468195e454f1794735231c443fd81b5da611bbcf2c98acb1ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
